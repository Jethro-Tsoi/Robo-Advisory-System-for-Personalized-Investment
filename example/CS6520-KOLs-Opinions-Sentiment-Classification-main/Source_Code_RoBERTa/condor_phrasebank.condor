requirements = (CUDADeviceName== "Tesla V100-SXM2-16GB")||(CUDADeviceName == "GeForce RTX 2080 Ti")||(CUDADeviceName == "Tesla V100S-PCIE-32GB")||(CUDADeviceName == "Tesla V100-SXM2-32GB")||(Machine == "v100c0.cs.cityu.edu.hk")||(Machine == "v100c1.cs.cityu.edu.hk")||(Machine == "v100c2.cs.cityu.edu.hk")||(Machine == "v100c3.cs.cityu.edu.hk")||(Machine == "v100c4.cs.cityu.edu.hk")||(Machine == "v100c5.cs.cityu.edu.hk")||(Machine == "v100c6.cs.cityu.edu.hk")||(Machine == "v100c7.cs.cityu.edu.hk")||(Machine == "v100b1.cs.cityu.edu.hk")||(Machine == "v100b2.cs.cityu.edu.hk")||(Machine == "v100b3.cs.cityu.edu.hk")||(Machine == "v100b4.cs.cityu.edu.hk")||(Machine == "v100b5.cs.cityu.edu.hk")||(Machine == "v100b6.cs.cityu.edu.hk")||(Machine == "v100b7.cs.cityu.edu.hk")
request_GPUs = 1

executable = /bin/sh
error  =  /public/wangyuchen/project/RoBERTa_sourceCode/log/condor_phraseBank.err
log    =  /public/wangyuchen/project/RoBERTa_sourceCode/log/condor_phraseBank.log
output =  /public/wangyuchen/project/RoBERTa_sourceCode/log/condor_phraseBank.out

arguments = /public/wangyuchen/project/RoBERTa_sourceCode/condor_phraseBank_train.sh
queue